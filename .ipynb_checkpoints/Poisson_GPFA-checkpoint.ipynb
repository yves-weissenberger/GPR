{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from skimage import data, color\n",
    "import scipy.ndimage as ndimage\n",
    "import h5py\n",
    "import scipy.io as spio\n",
    "import scipy as sp\n",
    "\n",
    "import sys\n",
    "import seaborn\n",
    "seaborn.set(font_scale=2)\n",
    "seaborn.set_style('whitegrid')\n",
    "clrs = seaborn.color_palette()\n",
    "from multiprocessing.dummy import Pool \n",
    "\n",
    "sys.path.append('/home/yves/Documents/')\n",
    "import twoptb as MP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Laplace Inference -----------------------------------------------------------\n",
    "def negLogPosteriorUnNorm(xbar, ybar, C_big, d_big, K_bigInv, xdim, ydim):\n",
    "    xbar = np.ndarray.flatten(np.asarray(xbar))\n",
    "    ybar = np.ndarray.flatten(np.asarray(ybar))\n",
    "    T = int(len(d_big)/ydim)\n",
    "\n",
    "    C_big = np.asarray(C_big)\n",
    "    d_big = np.asarray(d_big)\n",
    "\n",
    "    K_bigInv = np.asarray(K_bigInv)\n",
    "\n",
    "    A = np.dot(C_big.T, xbar) + d_big\n",
    "    Aexp = np.exp(A)\n",
    "\n",
    "    L1 = np.dot(Aexp, np.ones(ydim*T))\n",
    "    L2 = - np.dot(ybar, A.T)\n",
    "    L3 = 0.5*np.dot(xbar,np.dot(K_bigInv,xbar))\n",
    "\n",
    "    L = L1 + L2 + L3\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    return L\n",
    "\n",
    "def negLogPosteriorUnNorm_grad(xbar, ybar, C_big, d_big, K_bigInv, xdim, ydim):\n",
    "    xbar = np.asarray(xbar)\n",
    "    ybar = np.asarray(ybar)\n",
    "\n",
    "    A = np.dot(C_big.T, xbar) + d_big\n",
    "    A = np.float64(A)\n",
    "    Aexp = np.exp(A)\n",
    "\n",
    "    dL1 = np.dot(Aexp,C_big.T)\n",
    "    dL2 = - np.dot(ybar, C_big.T)\n",
    "    dL3 = np.dot(xbar, K_bigInv)\n",
    "\n",
    "    dL = dL1 + dL2 + dL3\n",
    "\n",
    "    return dL\n",
    "\n",
    "def negLogPosteriorUnNorm_hess(xbar, ybar, C_big, d_big, K_bigInv, xdim, ydim):\n",
    "    xbar = np.asarray(xbar)\n",
    "    ybar = np.asarray(ybar)\n",
    "\n",
    "    T = int(len(xbar)/xdim)\n",
    "\n",
    "    A = np.dot(C_big.T, xbar) + d_big\n",
    "    A = np.float64(A)\n",
    "\n",
    "    Aexp = np.exp(A)\n",
    "    Aexpdiagonal = sp.sparse.spdiags(Aexp,0,ydim*T,ydim*T)\n",
    "    temp = Aexpdiagonal.dot(C_big.T)\n",
    "\n",
    "    ddL = np.dot(C_big, temp) + K_bigInv\n",
    "\n",
    "    return ddL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplace(experiment,\n",
    "            params,\n",
    "            prevOptimRes = None,\n",
    "            returnOptimRes = True,\n",
    "            verbose = False,\n",
    "            optimMethod = 'Newton-CG'):\n",
    "    '''\n",
    "    laplaceInfRes, -post_lik = laplace(experiment, params)\n",
    "    '''\n",
    "    ridge = 0\n",
    "    \n",
    "    #here T is the number of bins ydim is the number of neurons\n",
    "    [ydim,T] = np.shape(experiment.data[0]['Y'])\n",
    "    [ydim, xdim] = np.shape(params['C'])     #xdim is the number of latent dimensions\n",
    "    numTrials = len(experiment.data)  # number of trials\n",
    "    trialDur = experiment.trialDur \n",
    "    binSize = experiment.binSize      # size of bins\n",
    "\n",
    "    # make big parameters\n",
    "    C_big, d_big = util.makeCd_big(params,T)\n",
    "    K_big, K = util.makeK_big(params, trialDur, binSize)\n",
    "    K_bigInv = np.linalg.inv(K_big)\n",
    "    \n",
    "    x_post_mean = []\n",
    "    x_post_cov = []\n",
    "    x_vsmGP = []\n",
    "    x_vsm = []\n",
    "\n",
    "    post_lik = 0\n",
    "    \n",
    "    # store current optimization result to use as initialization for inference in next EM iteration\n",
    "    lapOptimRes = []\n",
    "\n",
    "    for trial in range(numTrials):\n",
    "        if verbose: print('laplace inference trajectory of trial ' +str(trial+1) +'...')\n",
    "        y = experiment.data[trial]['Y']\n",
    "        ybar = np.ndarray.flatten(np.reshape(y, ydim*T))\n",
    "\n",
    "        if prevOptimRes == None:\n",
    "            xInit = np.ndarray.flatten(np.zeros([xdim*T,1]))\n",
    "        else:\n",
    "            xInit = prevOptimRes[trial]\n",
    "\n",
    "\n",
    "            \n",
    "        ####\n",
    "        resLap = op.minimize(\n",
    "            fun = negLogPosteriorUnNorm,\n",
    "            x0 = xInit,\n",
    "            method=optimMethod,\n",
    "            args = (ybar, C_big, d_big, K_bigInv, xdim, ydim),\n",
    "            jac = negLogPosteriorUnNorm_grad,\n",
    "            hess = negLogPosteriorUnNorm_hess,\n",
    "            options = {'disp': False,'maxiter': 10000})\n",
    "        lapOptimRes.append(resLap.x)\n",
    "        post_lik = post_lik + resLap.fun\n",
    "        x_post_mean.append(np.reshape(resLap.x,[xdim,T]))\n",
    "        hess = negLogPosteriorUnNorm_hess(resLap.x, ybar, C_big, d_big, K_bigInv, xdim, ydim)\n",
    "        PostCovGP = np.linalg.inv(hess)\n",
    "        \n",
    "        PostCovGP = PostCovGP + ridge*np.diag(np.ones(xdim*T))\n",
    "        x_post_cov.append(PostCovGP)\n",
    "\n",
    "        temp_vsmGP = np.zeros([T,T,xdim])\n",
    "        for kk in range(xdim):\n",
    "            temp_vsmGP[:,:,kk] = PostCovGP[kk*T:(kk+1)*T, kk*T:(kk+1)*T]\n",
    "        x_vsmGP.append(temp_vsmGP)\n",
    "\n",
    "        temp_vsm = np.zeros([T,xdim,xdim])\n",
    "        for kk in range(T):\n",
    "            temp_vsm[kk][:,:] = PostCovGP[kk::T,kk::T]\n",
    "        x_vsm.append(temp_vsm)\n",
    "        # pdb.set_trace()\n",
    "\n",
    "    post_lik = post_lik / numTrials\n",
    "    laplaceInfRes = {\n",
    "        'post_mean': x_post_mean,\n",
    "        'post_cov' : x_post_cov,\n",
    "        'post_vsm': x_vsm,\n",
    "        'post_vsmGP': x_vsmGP}\n",
    "\n",
    "    if returnOptimRes == True:\n",
    "        return laplaceInfRes, -post_lik, lapOptimRes\n",
    "    else:\n",
    "        return laplaceInfRes, -post_lik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeCd_big(params, T):\n",
    "    #Here T is the number of bins in the trial\n",
    "    C_big = np.kron(params['C'],np.eye(T)).T\n",
    "    d_big = np.kron(np.ndarray.flatten(params['d']),np.ones(T)).T\n",
    "return C_big, d_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeK_big(params, trialDur, binSize, epsNoise = 0.001):\n",
    "    [ydim,xdim] = np.shape(params['C'])\n",
    "    epsSignal = 1 - epsNoise\n",
    "    params['tau'] = np.ndarray.flatten(params['tau'])\n",
    "\n",
    "    T = range(0,int(trialDur/binSize))\n",
    "    K = np.zeros([xdim, len(T), len(T)])\n",
    "    K_big = np.zeros([xdim*len(T), xdim*len(T)])\n",
    "    \n",
    "    # Make small K (size TxT) for each xdim\n",
    "    for xd in range(xdim):\n",
    "        for i in T:\n",
    "            for j in T:\n",
    "                K[xd,i,j] = epsSignal*np.exp(-0.5*((T[i]*binSize-T[j]*binSize)**2/(params['tau'][xd]*1000)**2))\n",
    "        K[xd] = K[xd] + epsNoise * np.eye(len(T))\n",
    "\n",
    "    # Make big K\n",
    "    for xd in range(xdim):\n",
    "        K_big[xd*len(T):(xd+1)*len(T),xd*len(T):(xd+1)*len(T)] = K[xd]\n",
    "    \n",
    "    return K_big, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \"\"\"Parameters:\n",
    "    ===========\n",
    "      * xdim       : int, latent dimensionality to fit\n",
    "      * ydim       : int, number of neurons in the dataset\n",
    "      * experiment : (optional) If a third optional argument of util.dataset object is given, \n",
    "                     the fucntion returns a dictionary of parameters obtained by performing Poisson-\n",
    "                     PCA Leave this argument empty to initialize randomly.\n",
    "    Returns:\n",
    "    ========\n",
    "         A dictionary of model parameters.\n",
    "    \"\"\"\n",
    "if experiment == None:\n",
    "    print('Initializing parameters randomly..')\n",
    "    params = {\n",
    "        'C': np.random.rand(ydim,xdim)*2 - 1,\n",
    "        'd': np.random.randn(ydim)*2 - 2,\n",
    "        'tau': np.random.rand(xdim)*0.5} # seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
